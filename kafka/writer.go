package main

import (
	"context"
	"github.com/segmentio/kafka-go"
	"log"
	"time"
)

func main() {
	// to produce messages
	topic := "my-topic"
	// TODO: Партиционирование по типу события.
	// важно собирать и обрабатывать все события определённого типа вместе,
	//можно использовать тип события в качестве ключа для партиционирования.
	// Это упрощает агрегацию данных по типу события и позволяет быстро обрабатывать все события одного типа.
	// Регистрация, оплата и т.д.
	partition := 0

	conn, err := kafka.DialLeader(context.Background(), "tcp", "localhost:9094", topic, partition)
	if err != nil {
		log.Fatal("failed to dial leader:", err)
	}

	conn.SetWriteDeadline(time.Now().Add(1 * time.Second))
	// TODO: Kafka оптимизирована для высоких нагрузок. На начальном этапе, пологаем что,
	// клиенты (браузеры или мобильные приложения) могут отправлять события о просмотре напрямую в Kafka-топик.
	// Для этого достаточно создать API-прослойку, которая без преобразований будет передавать эти события в Kafka.
	//В будущем, с ростом числа пользователей, можно добавить буферизацию событий в эту прослойку.
	//Например,  при достижении порогового значения, сервис будет накапливать события, поступающие каждую секунду,
	//и записывать их в Kafka раз в минуту. Такой подход значительно снизит нагрузку на Kafka, но потребует
	// более сложной реализации.
	//В частности, необходимо обеспечить синхронизацию буферов в разных инстансах сервиса-прослойки.
	// Нужно также предусмотреть сценарии, когда один из инстансов выйдет из строя.
	_, err = conn.WriteMessages(
		kafka.Message{Value: []byte("one!")},
		kafka.Message{Value: []byte("two!")},
		kafka.Message{Value: []byte("three!")},
	)
	//TODO: Так как поток данных ожидается непрерывным, нужно проверить, что ваше приложение не «течёт».
	// То есть нужно внедрить средства мониторинга памяти приложения.
	if err != nil {
		log.Fatal("failed to write messages:", err)
	}

	if err := conn.Close(); err != nil {
		log.Fatal("failed to close writer:", err)
	}
}
